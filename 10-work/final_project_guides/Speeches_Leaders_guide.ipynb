{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeches Project Guide\n",
    "\n",
    "The ultimate goal of this project is to build a database of speeches by Barack Obama and George W. Bush or any other set of world leaders that you can find speech transcripts for.\n",
    "\n",
    "The key elements that you need to obtain are the date, location, and text of the speech. In the coding steps below I take you through the process of creating this database for Obama and Bush. The end goal, in the next week or so, is to create a map of speech locations for each leader so that you can click through and see the text of the speech. Your goal should be to obtain at least 20 speeches per person, and limit yourself to 2 or 3 leaders (if you are choosing to investigate other leaders). \n",
    "\n",
    "Beyond creating a simple map--with the bare necessities of location, time, and transcript--you may want to investigate the kind of event, the size of the audience, whether these are national or international speeches: any kind of categorizing that will potentially deepen our insight into and interpretation of the speeches. You may also choose to run simple processes/aggregations on the speeches like most-frequent-words, types of phrases, groups of words that you choose to search for in order to bring your own point of view to this exploration of the speeches.\n",
    "\n",
    "The programmatic journey for this project is relatively straightforward--especially if you choose Obama and Bush--but is quite open as far as how you want to interpret it. \n",
    "\n",
    "Below, I have outlined the methods for creating a database of speeches hosted on this site:\n",
    "\n",
    "https://americanrhetoric.com/barackobamaspeeches.htm\n",
    "\n",
    "https://americanrhetoric.com/gwbushspeeches.htm\n",
    "\n",
    "Understand that this site does not contain all speeches and is not an authoritative resource for speeches, but it does provide a potentially useful data set for mapping and exploration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1\n",
    "Scrape all of the necessary information from:\n",
    "\n",
    "https://americanrhetoric.com/barackobamaspeeches.htm\n",
    "\n",
    "and\n",
    "\n",
    "https://americanrhetoric.com/gwbushspeeches.htm\n",
    "\n",
    "You should result and a list of dictionaries for each case speech, along with the links to PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Import your scraping libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Write your scraping code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Print out your list of lists or dictionaries here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Import that database into pandas\n",
    "###Export/save as CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: Download the PDFs and transform them into text. \n",
    "See Guided_Project_Options.ipynb For instructions on how to do this. Using this method you need to have the **xpdf** tool installed on your command line. If you have homebrew installed it should be as easy as:\n",
    "\n",
    "`brew install xpdf`\n",
    "\n",
    "Note **XPDF** is not a python thing, it is a command line thing that you are executing in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code away!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: Clean up the text using regular expressions.\n",
    "Here we go: the text files that were extracted from the PDFs are messy, you do not need to get them perfect, but you need to clean them up enough so that you can zone in on the speeches themselves. \n",
    "\n",
    "Open up a simple text file in your own text editor and take a look at the patterns and what needs to be extracted. Begin with one file and develop regular expressions that will give you a clean speech. Once you have that working try looping through all of the text files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually you will want to loop through all of the text files and run the cleanup on all of them. But first just select one text file to open up and begin cleaning up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import the regular expression library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Open a text file from your computer\n",
    "f = open('/Users/YOU/Documents/columbia_syllabus/pdf/15-777_1b82.txt', 'r')\n",
    "sample_transcript = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Take a look at the text file\n",
    "sample_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Create regular expressions\n",
    "##In most cases you will want to remove \n",
    "##unnecessary text: re.subs()\n",
    "##Which is like replace() but with regex\n",
    "#will likely be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Once you have successfully cleaned up one text file\n",
    "#Try to loop through all of them!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Join your dataframe of clean speeches\n",
    "#With your original data frame\n",
    "#Join them on the PDF name."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
